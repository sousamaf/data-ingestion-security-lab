{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0429042",
   "metadata": {},
   "source": [
    "# Laboratório — Módulo I (Colab-ready)\n",
    "\n",
    "Este notebook contém **3 exemplos executáveis** para a aula:\n",
    "\n",
    "1) **Dados Estruturados (SQL/SQLite)** — *“Qual região possui o maior índice de assaltos nos últimos 6 meses?”*  \n",
    "2) **Dados Semi-estruturados (JSON → CSV)** — consumo de API pública e transformação de campos.  \n",
    "3) **Dados Não Estruturados (texto de redes sociais/conversas)** — extração de menções/hashtags e contagem simples.\n",
    "\n",
    "> Todos os blocos são **auto-contidos** e não exigem credenciais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d93ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Opcional) Garantir versões recentes das libs no Colab/local\n",
    "# !pip install --quiet pandas matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace0b2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3, re, json, io, ssl, urllib.request\n",
    "from datetime import datetime, timedelta\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"OK: libs carregadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af6a73c",
   "metadata": {},
   "source": [
    "## 1) Dados Estruturados — SQLite (consulta SQL)\n",
    "\n",
    "**Pergunta socrática:** *“Qual região possui o maior índice de assaltos nos últimos 6 meses?”*\n",
    "\n",
    "**Passos:**  \n",
    "- Criar um banco **SQLite** em memória com a tabela `boletins`.  \n",
    "- Inserir **dados sintéticos** (região, tipo, data).  \n",
    "- Rodar a consulta SQL com `GROUP BY` e `COUNT()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b08882",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criar e popular base SQLite em memória\n",
    "con = sqlite3.connect(\":memory:\")\n",
    "cur = con.cursor()\n",
    "\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE boletins (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    regiao TEXT,\n",
    "    tipo TEXT,\n",
    "    data_ocorrencia DATE\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Gerar dados sintéticos (~9 meses), com \"assalto\" mais frequente\n",
    "regioes = [\"Norte\", \"Sul\", \"Leste\", \"Oeste\", \"Centro\"]\n",
    "tipos = [\"assalto\", \"furto\", \"roubo\", \"ameaça\"]\n",
    "\n",
    "hoje = datetime.now().date()\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "rows = []\n",
    "for dia in range(270):  # ~9 meses\n",
    "    d = hoje - timedelta(days=dia)\n",
    "    for _ in range(random.randint(0, 3)):  # 0 a 3 ocorrências por dia\n",
    "        reg = random.choice(regioes)\n",
    "        t = random.choices(tipos, weights=[3,2,2,1])[0]  # \"assalto\" com maior peso\n",
    "        rows.append((reg, t, d))\n",
    "\n",
    "cur.executemany(\"INSERT INTO boletins (regiao, tipo, data_ocorrencia) VALUES (?, ?, ?)\", rows)\n",
    "con.commit()\n",
    "\n",
    "# Consulta: últimos ~6 meses (≈180 dias)\n",
    "seis_meses_atras = hoje - timedelta(days=180)\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT regiao, COUNT(*) AS ocorrencias\n",
    "FROM boletins\n",
    "WHERE tipo='assalto' AND date(data_ocorrencia) >= date(?)\n",
    "GROUP BY regiao\n",
    "ORDER BY ocorrencias DESC;\n",
    "\"\"\"\n",
    "\n",
    "df_sql = pd.read_sql_query(query, con, params=[seis_meses_atras.isoformat()])\n",
    "df_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a633c400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizar gráfico simples (sem definir cores explicitamente)\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(df_sql['regiao'], df_sql['ocorrencias'])\n",
    "plt.title(\"Assaltos por região — últimos ~6 meses (dados sintéticos)\")\n",
    "plt.xlabel(\"Região\")\n",
    "plt.ylabel(\"Ocorrências\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d58838",
   "metadata": {},
   "source": [
    "## 2) Dados Semi-estruturados — JSON → CSV\n",
    "\n",
    "**Pergunta socrática:** *“Como automatizar a leitura e padronização de dados em JSON de diferentes fontes?”*\n",
    "\n",
    "Neste exemplo, vamos:\n",
    "- **Baixar JSON** de uma API pública (JSONPlaceholder).  \n",
    "- Selecionar e **renomear campos** relevantes.  \n",
    "- **Exportar para CSV** e visualizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fa0dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://jsonplaceholder.typicode.com/posts\"\n",
    "print(\"Baixando:\", url)\n",
    "\n",
    "# Contexto SSL tolerante (alguns ambientes bloqueiam certificados)\n",
    "ctx = ssl.create_default_context()\n",
    "ctx.check_hostname = False\n",
    "ctx.verify_mode = ssl.CERT_NONE\n",
    "\n",
    "try:\n",
    "    with urllib.request.urlopen(url, context=ctx, timeout=15) as resp:\n",
    "        data = json.loads(resp.read().decode(\"utf-8\"))\n",
    "except Exception as e:\n",
    "    print(\"Falha ao baixar; usando amostra local:\", e)\n",
    "    data = [\n",
    "        {\"userId\": 1, \"id\": 1, \"title\": \"Relato de ocorrência A\", \"body\": \"Texto A\"},\n",
    "        {\"userId\": 2, \"id\": 2, \"title\": \"Relato de ocorrência B\", \"body\": \"Texto B\"}\n",
    "    ]\n",
    "\n",
    "# Selecionar/renomear campos\n",
    "registros = []\n",
    "for item in data:\n",
    "    registros.append({\n",
    "        \"usuario\": item.get(\"userId\"),\n",
    "        \"id\": item.get(\"id\"),\n",
    "        \"titulo\": item.get(\"title\"),\n",
    "        \"texto\": item.get(\"body\")\n",
    "    })\n",
    "\n",
    "df_json = pd.DataFrame(registros)\n",
    "df_json.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0911e3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exportar para CSV\n",
    "csv_path = \"posts_padronizados.csv\"\n",
    "df_json.to_csv(csv_path, index=False)\n",
    "print(\"CSV salvo em:\", csv_path)\n",
    "\n",
    "# Amostra\n",
    "df_json.sample(5, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bbb1cce",
   "metadata": {},
   "source": [
    "### Análise de Dados com `jq`\n",
    "\n",
    "O **`jq`** é uma ferramenta de linha de comando para processar arquivos **JSON** de forma rápida e estruturada, semelhante ao uso de `grep`, `awk` ou `sed`, mas voltada para dados em formato de objetos e listas.\n",
    "\n",
    "No contexto de **coleta e ingestão de dados**, ele é útil para:\n",
    "- Inspecionar o conteúdo bruto retornado por uma **API**;\n",
    "- Filtrar apenas campos relevantes (por exemplo, `id`, `title`, `userId`);\n",
    "- Reformatar ou transformar a saída antes de armazenar.\n",
    "\n",
    "A sintaxe básica é:\n",
    "```bash\n",
    "jq '<filtro>' arquivo.json\n",
    "```\n",
    "\n",
    "Exemplo:\n",
    "```bash\n",
    "jq '.[] | {usuario: .userId, titulo: .title}' posts.json\n",
    "```\n",
    "\n",
    "Dica: O jq está disponível nativamente em distribuições Linux e pode ser instalado no Google Colab com:\n",
    "```bash\n",
    "!apt-get install -y jq\n",
    "```\n",
    "\n",
    "A seguir, veremos um exemplo prático filtrando apenas alguns campos de um arquivo JSON exportado do nosso DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7551b431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar o jq (apenas na primeira execução)\n",
    "# !apt-get install -y jq > /dev/null\n",
    "\n",
    "# Salvar o JSON da API\n",
    "with open(\"posts.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(data[:5], f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# Filtrar campos usando jq\n",
    "!jq -r '.[] | \"\\(.userId): \\(.title)\"' posts.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b26047b1",
   "metadata": {},
   "source": [
    "## 3) Dados Não Estruturados — Texto (redes sociais / conversas)\n",
    "\n",
    "**Pergunta socrática:** *“O que as redes sociais anunciam antes do boletim oficial?”*\n",
    "\n",
    "Neste exemplo simples:\n",
    "- Recebemos uma lista de **postagens** (texto livre).  \n",
    "- Extraímos **menções (@)** e **hashtags (#)** com regex.  \n",
    "- Contamos frequências e visualizamos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6172a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = [\n",
    "    \"Ocorrência em #Palmas ontem à noite. Patrulha já em ação. @delegacia_to\",\n",
    "    \"Relato de furto no centro de #Araguaina. Testemunhas mencionam veículo preto. @pm_to\",\n",
    "    \"Discussão sobre segurança em #Gurupi; evento marcado para amanhã. @org_publico\",\n",
    "    \"Vídeo circulando de suposto assalto em #Palmas — confirmar com boletim oficial.\",\n",
    "    \"Reforço no policiamento em #Palmas após série de furtos. @ssp_to @delegacia_to\"\n",
    "]\n",
    "\n",
    "def extract_mentions_hashtags(texts):\n",
    "    mentions, hashtags = [], []\n",
    "    for t in texts:\n",
    "        mentions += re.findall(r\"@([A-Za-z0-9_\\.]+)\", t)\n",
    "        hashtags += re.findall(r\"#(\\w+)\", t, flags=re.UNICODE)\n",
    "    return mentions, hashtags\n",
    "\n",
    "mentions, hashtags = extract_mentions_hashtags(posts)\n",
    "\n",
    "pd.DataFrame({\n",
    "    \"tipo\": [\"menções\", \"hashtags\"],\n",
    "    \"itens\": [mentions, hashtags]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b14eed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "c_hashtags = Counter(hashtags)\n",
    "df_hash = pd.DataFrame(c_hashtags.items(), columns=[\"hashtag\", \"freq\"]).sort_values(\"freq\", ascending=False)\n",
    "\n",
    "c_mentions = Counter(mentions)\n",
    "df_mentions = pd.DataFrame(c_mentions.items(), columns=[\"mencao\", \"freq\"]).sort_values(\"freq\", ascending=False)\n",
    "\n",
    "print(\"Top hashtags:\")\n",
    "display(df_hash)\n",
    "\n",
    "print(\"Top menções:\")\n",
    "display(df_mentions)\n",
    "\n",
    "# Visualização das hashtags\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(df_hash['hashtag'], df_hash['freq'])\n",
    "plt.title(\"Frequência de hashtags (amostra simulada)\")\n",
    "plt.xlabel(\"Hashtag\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f83be6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpuTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
